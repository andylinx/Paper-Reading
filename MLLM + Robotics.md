## MLLM + Robotic Manipulation



1. (2023.12) **ManipLLM**: Embodied Multimodal Large Language Model for Object-Centric Robotic Manipulation [[Paper]](https://arxiv.org/abs/2312.16217) [[Project]](https://sites.google.com/view/manipllm)
2. (2024.3) **ManipVQA**: Injecting Robotic Affordance and Physically Grounded Information into Multi-Modal Large Language Models [[Paper]](https://arxiv.org/abs/2405.17418) 
3. (2024.5) **Self-Corrected** Multimodal Large Language Model for End-to-End Robot Manipulation [[Paper]](https://arxiv.org/abs/2405.17418) 
4. (2024.5) **SAM-E**: Leveraging Visual Foundation Model with Sequence Imitation for Embodied Manipulation [[Paper]](https://arxiv.org/abs/2405.19586) [[Project]](https://sam-embodied.github.io/)

