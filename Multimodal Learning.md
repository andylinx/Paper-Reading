# Multimodal Data Learning

1. (2020.11) Diverse Image Captioning with Context-Object Split Latent Spaces [[Paper]](https://arxiv.org/pdf/2011.00966)
2. (2024.4) Propensity Score Alignment of Unpaired Multimodal Data [[Paper]](https://arxiv.org/abs/2404.01595v1)
3. (2024.4) TextSquare: Scaling up Text-Centric Visual Instruction Tuning [[Paper]](https://arxiv.org/pdf/2404.12803)
4. (2023.5) **Pre-Trained Vision-Language Models as Partial Annotators** [[Paper]](https://arxiv.org/pdf/2406.18550)
5. (2024.6) Multimodal Task Vectors Enable Many-Shot Multimodal In-Context Learning [[Paper]](https://arxiv.org/abs/2406.15334) 
6. (2024.6) **Semi-supervised Concept Bottleneck Models** [[Paper]](https://arxiv.org/pdf/2406.18992)
7. (2024.6) **OpenDlign: Enhancing Open-World 3D Learning with Depth-Aligned Images** [[Paper]](https://arxiv.org/abs/2404.16538)
8. (2024.6) From the Least to the Most: Building a Plug-and-Play Visual Reasoner via Data Synthesis [[Paper]](https://arxiv.org/abs/2406.19934) [[Project]](https://github.com/steven-ccq/VisualReasoner)
9. (2024.6) MM-Instruct: Generated Visual Instructions for Large Multimodal Model Alignment [[Paper]](https://arxiv.org/abs/2406.19736) [[Project]](https://github.com/jihaonew/MM-Instruct)
10. (2024.7) Robust Multimodal Learning via Representation Decoupling [[Paper]](https://arxiv.org/pdf/2407.04458)





### New learning paradigms



1. (2024.6) Pairwise Difference Learning for Classification [[Paper]](https://arxiv.org/abs/2406.20031v1)